# Создание системы для автоматического распознавания и классификации видеозаписей на основе содержания и контента(Лабораторная №3).

  Этот проект представляет собой систему для автоматического распознавания и классификации объектов на видеозаписях с использованием предварительно обученной модели глубокого   обучения. Для анализа каждого кадра видео использовалась готовая модель MobileNetV2, которая была обучена на большом наборе изображений ImageNet. 

## MobileNetV2.

*MobileNetV2* - это модель глубокого обучения, представляющая собой архитектуру сверточной нейронной сети (CNN), предназначенную для выполнения задачи классификации изображений. Эта модель была разработана компанией Google и представляет собой улучшенную версию оригинальной архитектуры MobileNet.

Основные характеристики: 

 * *Эффективность по размеру.* Одним из основных преимуществ MobileNetV2 является его эффективность по размеру. Модель создана таким образом, чтобы обеспечивать высокую точность классификации при минимальном размере модели, что полезно для различных задач на мобильных устройствах и в условиях ограниченных ресурсов.

  * *Inverted Residuals.* В MobileNetV2 используется концепция "Inverted Residuals" (инвертированных остаточных блоков). Это позволяет сети эффективно передавать информацию между слоями и улучшает обучение.

  * *Блоки Bottleneck.* Архитектура MobileNetV2 включает в себя блоки "Bottleneck", которые помогают снизить количество параметров и вычислительных затрат, что важно для мобильных и встраиваемых устройств.

  * *Преобразование с точностью к битам.* MobileNetV2 включает в себя методы калибровки сжатия для уменьшения точности к битам (quantization-aware training), что позволяет дополнительно уменьшить размер модели без значительной потери качества.

  * *Использование функций активации ReLU6.* В качестве функций активации используется ReLU6, что также способствует стабильному обучению и предотвращает проблемы с взрывом градиентов.

MobileNetV2 обучается на больших наборах данных изображений (например, ImageNet) и может быть использован для классификации объектов на новых изображениях. Он часто применяется в мобильных приложениях, встраиваемых системах и других сценариях, где важна эффективность по размеру и вычислительная эффективность.

## ImageNet.

ImageNet - это крупный набор данных изображений, предназначенный для разработки и оценки алгоритмов компьютерного зрения и глубокого обучения. Этот набор данных содержит миллионы изображений, классифицированных в тысячи категорий или классов.

Основные характеристики ImageNet:

* *Объем данных.* ImageNet является одним из самых крупных и широко используемых наборов данных в области компьютерного зрения. Он содержит более миллиона изображений, представляющих богатый спектр объектов и сцен.
* *Классификация и локализация.* Изначально ImageNet был создан для задачи классификации изображений, то есть для определения, к какому классу (категории) принадлежит каждое изображение. Однако, в дополнение к классификации, в ImageNet также присутствуют изображения с разметкой для задачи локализации объектов (Bounding Box), где помимо классификации указываются координаты ограничивающего прямоугольника вокруг объекта.
* *Разнообразие данных.* ImageNet включает в себя изображения различных объектов и сцен, что обеспечивает разнообразие данных для обучения и тестирования моделей. В наборе данных представлены изображения животных, транспортных средств, людей, растений и других объектов.
* *Доступность.* ImageNet доступен для общественности и исследовательского использования. Многие библиотеки глубокого обучения, такие как TensorFlow и PyTorch, предоставляют инструменты для загрузки и использования данных из ImageNet.

ImageNet является важным ресурсом для разработки и тестирования алгоритмов машинного зрения и глубокого обучения.

## MoviePy.

MoviePy - это библиотека на языке программирования Python, предназначенная для обработки и редактирования видео. Она обеспечивает простой и удобный интерфейс для работы с видеофайлами, включая создание, редактирование, конкатенацию, наложение звука, добавление текста и многие другие операции.

Некоторые ключевые возможности библиотеки MoviePy:

* *Простота использования.* MoviePy обладает простым синтаксисом и хорошей документацией, что делает ее доступной для широкого круга пользователей.
* *Многофункциональность.* Библиотека предоставляет возможность выполнять множество операций с видео, включая обработку каждого кадра, создание анимаций, конкатенацию видеофайлов, добавление звука, наложение текста и графики, изменение размера видео и многое другое.
* *Интеграция с другими библиотеками.* MoviePy легко интегрируется с другими библиотеками Python, такими как NumPy, SciPy, Pillow и другими.
* *Возможность визуализации в Jupyter Notebook.* MoviePy предоставляет метод ipython_display(), который упрощает визуализацию видео в средах, поддерживающих IPython, таких как Jupyter Notebook.


## Как работает программа:
1. **Установка библиотек.**
    * Устанавливаем необходимые библиотеки, такие как 'opencv', 'tensorflow', 'pillow' и 'moviepy'. Эти библиотеки используются для обработки видео, работы с моделью глубокого обучения (MobileNetV2), и отображения результатов.

2. **Импорт библиотек.**
   * Импортируем необходимые библиотеки, включая 'cv2', 'MobileNetV2', 'preprocess_input', 'decode_predictions' из TensorFlow, 'image' из keras.preprocessing, 'numpy', 'Image' из Pillow, и 'VideoFileClip' из moviepy.editor.

3. **Загрузка предварительно обученной модели MobileNetV2.**
   * Загружаем предварительно обученную модель MobileNetV2 из библиотеки TensorFlow в переменную 'model'. Эта модель была обучена на большом наборе данных ImageNet и способна классифицировать объекты.
  
4. **Функция классификации видеокадра.**
    * Определяем функцию 'classify_frame', которая принимает видеокадр, предобрабатывает его и использует модель MobileNetV2 для предсказания класса объекта на кадре. Функция возвращает текстовую информацию о классе и вероятности.
  
5. **Функция обработки каждого кадра.** 
    * Определяем функцию 'process_frame', которая принимает кадр видео, выполняет классификацию объектов с использованием classify_frame, добавляет текстовую информацию о классе и вероятности на кадр, и возвращает обработанный кадр.
  
6. **Загрузка видеофайла.**
    * Загружаем видеофайл с использованием 'VideoFileClip' из библиотеки MoviePy. Укажите путь к вашему видеофайлу.
  
7. **Обработка видеофайла.**
    * Проходим по каждому кадру видео, применяя функцию 'process_frame' к каждому кадру. Это создаст новый видеофайл, в котором каждый кадр содержит добавленную текстовую информацию о классе и вероятности. Это сделано для того, чтобы смотреть результаты не покадрово, а цельным видео.
  
8. **Визуализация результатов.**
    * Отображаем обработанное видео с помощью метода ipython_display() из объекта 'VideoClip'. Обратите внимание, что это может быть доступно только в интерактивных средах, таких как Jupyter Notebook.



